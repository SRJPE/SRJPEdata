arrange(fish_id) %>%
pull(fish_id)
# Create matrix of all combinations of fish and GEN
EH <- expand.grid(
fish,
reach.meta.aggregate$GEN, stringsAsFactors = FALSE
)
names(EH) <- c('FishID', 'GEN')
# Add col detect to min_detects, these fish get a 1
min_detects$detect <- 1
# Join in detections to the matrix, fish detected a GEN will be given a 1
# otherwise it will be given a 0
EH <- EH %>%
left_join(
min_detects %>%
select(
FishID, GEN, detect
), by = c("FishID", "GEN")
) %>%
# Replace NA with 0 https://stackoverflow.com/questions/28992362/dplyr-join-define-na-values
mutate_if(
is.numeric, coalesce, 0
)
# Reshape the df wide, so that columns are GEN locations, rows are fish,
# values are 1 or 0 for presence/absence
EH <- reshape(EH, idvar = 'FishID', timevar = 'GEN', direction = 'wide')
colnames(EH) <- gsub('detect.', '', colnames(EH))
# Manually make the release column a 1 because all fish were released there
# sometimes detections df does not reflect that accurately
EH[2] <- 1
EH
}
create_inp <- function(detections, EH) {
# Create an inp df
#
# Arguments:
#  detections: a detections df (make sure to use the aggregated version)
#  EH: an encounter history df
#
# Return:
#  inp df i.e. Fish01 | 11101, a record of a fish and it's presence/absence
#  at each given receiver location.
EH.inp <- EH %>%
# Collapse the encounter columns into a single column of 1's and 0's
unite("ch", 2:(length(EH)), sep ="") %>%
# Use the detections df to get the StudyID assignment
mutate(StudyID = unique(detections$StudyID))
EH.inp
}
reciever_metadata
reciever_data
fish
detections_metadata
# TEST OUT ONE TO MATCH FLORAS TABLE -
coleman_detections <- purrr::map("ColemanFall_2013", pull_detections_data) |>
reduce(bind_rows) |>
glimpse()
# Clean up
formatted_spring_detections <- coleman_detections |>
mutate(first_time = as.POSIXct(first_time,
format = "%m/%d/%Y %H:%M:%S",
tz = "Etc/GMT+8"),
last_time = as.POSIXct(last_time,
format = "%m/%d/%Y %H:%M:%S",
tz = "Etc/GMT+8"),
time = as.POSIXct(time,
format = "%m/%d/%Y %H:%M:%S",
tz = "Etc/GMT+8")) |>
glimpse()
# Join all tables together to get detections associated with fish releases
joined_detections <- fish |>
inner_join(formatted_spring_detections,
by = c("study_id" = "study_id",
"fish_id" = "fish_id")) |> # Used inner join because that is what the example ERDAPP script was doing, think through this more
left_join(reciever_data,
by = c("dep_id" = "dep_id")) |>
mutate(latitude = as.numeric(latitude),
longitude = as.numeric(longitude)) |>
glimpse()
#### Make a map of detection locations ####
dat <- tabledap('FEDcalFishTrack', url = "http://oceanview.pfeg.noaa.gov/erddap/", 'general_location="MiddleRiver"', fields = c("TagCode","Study_ID"))
#### Make a map of detection locations ####
dat <- tabledap('FEDcalFishTrack', url = "http://oceanview.pfeg.noaa.gov/erddap/", 'Study_ID="Juv_Green_Sturgeon_2018"')
pkgdown::build_site()
# glimpse(recaptured)
#
#
# ENV
environmental_gage <- dbGetQuery(con, "SELECT e.date, tl.stream, tl.site, tl.subsite, tl.site_group,
e.gage_id, ep.definition as parameter, e.value
FROM environmental_gage e
left join trap_location tl on e.trap_location_id = tl.id
left join environmental_parameter ep on e.parameter_id = ep.id")
# Pull data from Azure Database
library(DBI)
library(tidyverse)
library(lubridate)
# Use DBI - dbConnect to connect to database - keep user id and password sectret
con <- DBI::dbConnect(drv = RPostgres::Postgres(),
host = "jpe-db.postgres.database.azure.com",
dbname = "postgres",
user = Sys.getenv("jpe_db_user_id"),
password = Sys.getenv("jpe_db_password"),
port = 5432)
# glimpse(recaptured)
#
#
# ENV
environmental_gage <- dbGetQuery(con, "SELECT e.date, tl.stream, tl.site, tl.subsite, tl.site_group,
e.gage_id, ep.definition as parameter, e.value
FROM environmental_gage e
left join trap_location tl on e.trap_location_id = tl.id
left join environmental_parameter ep on e.parameter_id = ep.id")
# TODO add in gage source - left join gage_source gs on e.gage_id = gs.id
glimpse(environmental_gage)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(googleCloudStorageR)
library(CDECRetrieve)
library(lubridate)
library(hms)
feather_rst <- rst_enviro %>%
filter(stream == "feather river", parameter == "temperature") %>%
select(stream, site, subsite, date, value) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
filter(mean_temp_degC > 0) %>%
glimpse
feather_rst <- trap %>% glimpse()
feather_rst <- trap %>% glimpse()
feather_rst <- trap %>%
filter(stream == "feather river") %>%
select(stream, site, subsite, date, water_temp) %>%
rename(mean_temp_degC = water_temp) %>%
mutate(source = "RST environmental") %>%
filter(mean_temp_degC > 0) %>%
glimpse
feather_rst <- trap %>% glimpse()
filter(stream == "feather river") %>%
select(stream, site, subsite, date = trap_start_date, water_temp) %>%
rename(mean_temp_degC = water_temp) %>%
mutate(source = "RST environmental") %>%
filter(mean_temp_degC > 0) %>%
glimpse()
feather_rst <- trap %>% glimpse()
feather_rst <- trap %>%
filter(stream == "feather river") %>%
select(stream, site, subsite, date = trap_start_date, water_temp) %>%
rename(mean_temp_degC = water_temp) %>%
mutate(source = "RST environmental") %>%
filter(mean_temp_degC > 0) %>%
glimpse()
feather_rst <- trap %>%
filter(stream == "feather") %>%
select(stream, site, subsite, date = trap_start_date, water_temp) %>%
rename(mean_temp_degC = water_temp) %>%
mutate(source = "RST environmental") %>%
filter(mean_temp_degC > 0) %>%
glimpse()
feather_rst <- trap %>% glimpse()
feather_rst$stream |> unique()
feather_rst <- trap %>%
filter(stream == "feather river") %>% glimpse()
feather_rst <- trap %>%
filter(stream == "feather river") %>%
select(stream, site, subsite, date = trap_start_date, water_temp) %>%
rename(mean_temp_degC = water_temp) %>%
mutate(source = "RST environmental") %>% glimpse()
filter(!is.na(mean_temp_degC))
filter(!is.na(feather_rst$mean_temp_degC))
# source USGS
mill <- read_rds(here::here("data-raw", "standard-format-data-prep","temp_data", "mill_temp.rds"))
mill
MLM_CDEC <- cdec_query(station = "MLM", dur_code = "H", sensor_num = "25", start_date = "1996-01-01")
MLM_daily_temps <- MLM_hourly_temps %>%
group_by(date) %>%
summarize(mean_temp_degC = mean(temp_degC),
max_temp_degC = max(temp_degC))
MLM_hourly_temps <- MLM_CDEC %>%
mutate(date = as_date(datetime),
time = as_hms(datetime),
temp_degC = fahrenheit.to.celsius(parameter_value, round = 1)) %>%
select(date,time,temp_degC)
MLM_daily_temps <- MLM_hourly_temps %>%
group_by(date) %>%
summarize(mean_temp_degC = mean(temp_degC),
max_temp_degC = max(temp_degC))
# source
mill_format <- MLM_daily_temps %>%
mutate(stream = "mill creek",
site = stream,
subsite = site,
source = "CDEC MLM") %>%
filter(mean_temp_degC > 0 & mean_temp_degC < 35,
max_temp_degC > 0 & max_temp_degC < 35) %>%
glimpse()
summary(mill_format$date)
mill_format %>% ggplot() +
geom_line(aes(x = date, y = mean_temp_degC), color = "gray") +
# geom_point(aes(x = date, y = mean_temp_degC), size = .001) +
theme_minimal()
### USGS 11390500
# Read created CSV
WLK_USGS <- readNWISdv(11390500, "00010")
library(dataRetrieval)
### USGS 11390500
# Read created CSV
WLK_USGS <- readNWISdv(11390500, "00010")
# Format to make tidier
sac_usgs_format <- WLK_USGS %>%
select(Date, temp_degC =  X_00010_00003) %>%
as_tibble() %>%
rename(date = Date,
mean_temp_degC = temp_degC) %>%
mutate(stream = "sacramento river",
source = "USGS 11390500") %>%
#filter(year(date) > 2000) %>% # filter to greater than 2000
glimpse
# Format to make tidier
sac_usgs_format <- WLK_USGS %>%
select(Date, temp_degC =  X_00010_00003) %>%
as_tibble() %>%
rename(date = Date,
mean_temp_degC = temp_degC) %>%
mutate(stream = "sacramento river",
source = "USGS 11390500") %>%
#filter(year(date) > 2000) %>% # filter to greater than 2000
glimpse
# Plot
ggplot() +
geom_line(data = sac_usgs_format, aes(x = date, y = mean_temp_degC), color = "black") +
labs(x = "date",
y = "Temperature (deg C)",
caption = "USGS 11390500")
sac_rst_format <- trap %>%
filter(stream == "sacramento river") %>% glimpse()
select(stream, date, value = water_temp) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
glimpse
sac_rst_format <- trap %>%
filter(stream == "sacramento river") %>%
select(stream, date, value = water_temp) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
glimpse
sac_rst_format <- trap %>% glimpse()
sac_rst_format <- trap %>%
filter(stream == "sacramento river") %>%
select(stream, date = trap_stop_date, value = water_temp) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
glimpse
sac_rst_format <- trap %>%
filter(stream == "sacramento river") %>%
select(stream, date = trap_stop_date, value = water_temp) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
glimpse
summary(sac_rst_format$date)
summary(sac_rst_format$date)
ggplot() +
geom_line(data = sac_rst_format, aes(x = date, y = mean_temp_degC))
sac_format <- bind_rows(sac_rst_format, # rst
sac_usgs_format) %>%
group_by(stream, date, mean_temp_degC, source) |>
distinct()
sac_format <- bind_rows(sac_rst_format, # rst
sac_usgs_format) %>%
group_by(stream, date, mean_temp_degC, source) |>
distinct()
# need to apply values for all sacramento sites and subsites
sac_sites <- filter(catch, stream == "sacramento river") |>
select(stream, site, subsite) |>
distinct()
sac_format_all <- full_join(sac_format, sac_sites)
summary(sac_format_all$date)
ggplot() +
geom_line(data = sac_format_all, aes(x = date, y = mean_temp_degC, color = site))
yuba_rst_format <- trap %>%
filter(stream == "yuba river") %>%
select(stream, site, subsite, date, value = water_temp) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
glimpse
yuba_rst_format <- trap %>%
filter(stream == "yuba river") %>%
select(stream, site, subsite, date = trap_stop_date, value = water_temp) %>%
rename(mean_temp_degC = value) %>%
mutate(source = "RST environmental") %>%
glimpse
summary(yuba_rst_format$date)
ggplot() +
geom_line(data = yuba_rst_format, aes(x = date, y = mean_temp_degC))
#cdec_datasets('YRS')
cdec_yrs <- cdec_query(station = "YRS", dur_code = "H", sensor_num = "25", start_date = "1996-01-01")
## TODO: convert to C from F
cdec_yrs_format <- cdec_yrs %>%
rename(source = agency_cd,
site = location_id,
temperature_c = parameter_value,
date = datetime) %>%
mutate(date = as_date(date),
temperature_c = (temperature_c-32 * 5/9)) %>%
group_by(date) %>%
mutate(mean_temp_degC = mean(temperature_c, na.rm = TRUE),
max_temp_degC = max(temperature_c, na.rm = TRUE)) %>%
filter(mean_temp_degC > 0) %>%
glimpse
summary(cdec_yrs_format)
ggplot() +
geom_line(data = cdec_yrs_format, aes(x = date, y = mean_temp_degC))
summary(combined_temp)
combined_temp <- bind_rows(battle_format,
butte_format_all,
clear_format,
deer_format,
feather_rst,
mill_format,
sac_format_all,
#yuba_format,
yuba_rst_format
) %>%
rename(mean_daily_temp_c  = mean_temp_degC,
max_daily_temp_c = max_temp_degC) %>%
glimpse()
# TODO feather flow is not in the database, need to add! currently all NA
feather_rst <- trap %>%
filter(stream == "feather river") %>%
select(stream, site, subsite, date = trap_start_date, water_temp) %>%
rename(mean_temp_degC = water_temp) %>%
mutate(source = "RST environmental") %>% glimpse()
filter(mean_temp_degC > 0) %>%
glimpse()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(googleCloudStorageR)
library(CDECRetrieve)
library(lubridate)
library(hms)
library(dataRetrieval)
gcs_auth(json_file = Sys.getenv("GCS_AUTH_FILE"))
gcs_global_bucket(bucket = Sys.getenv("GCS_DEFAULT_BUCKET"))
# get data from google cloud
# TODO update once battle and clear are in database
gcs_get_object(object_name = "environmental/data-raw/battle_clear_RSTTEMPS_07052022.xlsx",
bucket = gcs_get_global_bucket(),
saveToDisk =  here::here("data-raw", "temperature-data", "battle_clear_temp.xlsx"),
overwrite = TRUE)
# get data from google cloud
# TODO update once battle and clear are in database
gcs_get_object(object_name = "environmental/data-raw/battle_clear_RSTTEMPS_07052022.xlsx",
bucket = gcs_get_global_bucket(),
saveToDisk =  here::here("data-raw", "temperature-data", "battle_clear_temp.xlsx"),
overwrite = TRUE)
ubc_temp_raw <- readxl::read_excel(here::here("data-raw",
"temperature-data",
"battle_clear_temp.xlsx"), sheet = 4)
battle_format <- ubc_temp_raw %>%
rename(date = DT,
temp_c = TEMP_C) %>%
mutate(stream = "battle creek",
site = "ubc",
subsite = "ubc",
date = as.Date(date),
source = "FWS") %>%
group_by(date, stream, site, source, subsite) %>%
summarise(mean_temp_degC = mean(temp_c, na.rm = T),
max_temp_degC = max(temp_c, na.rm = T)) %>%
filter(mean_temp_degC > 0) %>%
glimpse
summary(battle_format)
battle_format %>% ggplot() +
geom_line(aes(x = date, y = mean_temp_degC, color = site)) +
# geom_point(aes(x = date, y = mean_temp_degC), size = .001) +
theme_minimal()
filter(catch, stream == "battle creek") |> distinct(site, subsite)
source(here("data-raw", "pull_tables_from_database.R"))
source(here::here("data-raw", "pull_tables_from_database.R"))
SRJPEdata::fahrenheit_to_celsius
SRJPEdata::fahrenheit_to_celsius
#'
#' @param celsius A numeric value representing the temperature in Celsius.
#'
#' @return A numeric value representing the temperature in Fahrenheit.
#'
#' @examples
#' celsius_to_fahrenheit(0) # Should return 32
#' celsius_to_fahrenheit(100) # Should return 212
#'
#' @export
celsius_to_fahrenheit <- function(celsius) {
fahrenheit <- (celsius * 9/5) + 32
return(fahrenheit)
}
#'
#' @param celsius A numeric value representing the temperature in Celsius.
#'
#' @return A numeric value representing the temperature in Fahrenheit.
#'
#' @examples
#' celsius_to_fahrenheit(0) # Should return 32
#' celsius_to_fahrenheit(100) # Should return 212
#'
#' @export
celsius_to_fahrenheit <- function(celsius) {
fahrenheit <- (celsius * 9/5) + 32
return(fahrenheit)
}
#'
#' @param fahrenheit A numeric value representing the temperature in Fahrenheit.
#'
#' @return A numeric value representing the temperature in Celsius.
#'
#' @examples
#' fahrenheit_to_celsius(32) # Should return 0
#' fahrenheit_to_celsius(212) # Should return 100
#'
#' @export
fahrenheit_to_celsius <- function(fahrenheit) {
celsius <- (fahrenheit - 32) * 5/9
return(celsius)
}
devtools::document()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(googleCloudStorageR)
library(CDECRetrieve)
library(lubridate)
library(hms)
library(dataRetrieval)
library(SRJPEdata)
source(here::here("data-raw", "pull_tables_from_database.R"))
# get data from google cloud
# TODO update once battle and clear are in database
# gcs_get_object(object_name = "environmental/data-raw/battle_clear_RSTTEMPS_07052022.xlsx",
#                bucket = gcs_get_global_bucket(),
#                saveToDisk =  here::here("data-raw", "temperature-data", "battle_clear_temp.xlsx"),
#                overwrite = TRUE)
ubc_temp_raw <- readxl::read_excel(here::here("data-raw",
"temperature-data",
"battle_clear_temp.xlsx"), sheet = 4)
battle_format <- ubc_temp_raw %>%
rename(date = DT,
temp_c = TEMP_C) %>%
mutate(stream = "battle creek",
site = "ubc",
subsite = "ubc",
date = as.Date(date),
source = "FWS") %>%
group_by(date, stream, site, source, subsite) %>%
summarise(mean_temp_degC = mean(temp_c, na.rm = T),
max_temp_degC = max(temp_c, na.rm = T)) %>%
filter(mean_temp_degC > 0) %>%
glimpse
summary(battle_format)
battle_format %>% ggplot() +
geom_line(aes(x = date, y = mean_temp_degC, color = site)) +
# geom_point(aes(x = date, y = mean_temp_degC), size = .001) +
theme_minimal()
# filter(catch, stream == "battle creek") |> distinct(site, subsite)
# Script to pull and process acoustic tagging data from ERDDAP NOAA
# Load in packages
# install.packages("RMark")
library(RMark) # For running program MARK
library(tidyverse) # Data manipulations
# install.packages("rerddap")
library(rerddap) # To retrieve NOAA ERDDAP data
library(lubridate) # Date time manipulations
library(leaflet) # To visualize receiver locations quickly on a map
library(vroom) # Read CSV's quickly
### Clear Cache
# First clear cache or it will repull old data
cache_delete_all()
# Set erddap url to use in pull data functions
erddap_url <- "https://oceanview.pfeg.noaa.gov/erddap/"
# TAGGED FISH TABLE
# metadata for JSATS tagged fish table
fish_metadata <- info('FED_JSATS_taggedfish', url = erddap_url)
# load in table
fish <- tabledap(fish_metadata, url = erddap_url)
updated_fish <- fish |>
mutate(fish_release_date = as.POSIXct(fish_release_date,
format = "%m/%d/%Y %H:%M:%S",
tz = "Etc/GMT+8"),
fish_date_tagged = as.POSIXct(fish_date_tagged,
format = "%m/%d/%Y %H:%M:%S",
tz = "Etc/GMT+8"),
fish_id_prefix = substr(fish_id, start = 1, stop = (nchar(fish_id)-4))) |>
glimpse()
# RECEIVER TABLE
# metadata for JSATS recievers table
reciever_metadata <- info('FED_JSATS_receivers', url = erddap_url)
reciever_data <- tabledap(reciever_metadata, url = erddap_url)
# Establish ERDDAP url and database name
detections_metadata <- info('FED_JSATS_detects', url = erddap_url)
# detections columns
detections_metadata$variables
# Retrieve list of all studyIDs on FED_JSATS
study_ids <- tabledap(detections_metadata,
fields = "study_id",
url = erddap_url) |>
pull(study_id) |>
unique()
ids_with_spring <- which(str_detect(study_ids, "Spring"))
spring_ids <- study_ids[ids_with_spring]
pull_detections_data <- function(study_id_list){
data <- tabledap('FED_JSATS_detects',
url = erddap_url,
str2lang(noquote(paste0("'study_id=\"", study_id_list,"\"'"))))
return(data)
}
