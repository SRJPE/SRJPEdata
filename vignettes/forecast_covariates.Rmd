---
title: "Covariate Development for Forecast Models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Covariate Development for Forecast Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE, 
  message = FALSE,
  echo = FALSE,
  comment = "#>", 
  fig.width=8, fig.height=5)

library(tidyverse)
library(SRJPEdata)
library(lubridate)
library(CDECRetrieve)
library(dplyr)
library(dataRetrieval)

colors_full <-  c("#9A8822", "#F5CDB4", "#F8AFA8", "#FDDDA0", "#74A089", #Royal 2
                  "#899DA4", "#C93312", "#DC863B", # royal 1 (- 3)
                  "#F1BB7B", "#FD6467", "#5B1A18", # Grand Budapest 1 (-4)
                  "#D8B70A", "#02401B", "#A2A475", # Cavalcanti 1
                  "#E6A0C4", "#C6CDF7", "#D8A499", "#7294D4", #Grand Budapest 2
                  "#9986A5", "#EAD3BF", "#AA9486", "#B6854D", "#798E87" # Isle of dogs 2 altered slightly
)

sr_covariates <- SRJPEdata::stock_recruit_covariates
```

# Process for developing forecast covariates

The diagram outlines the process for developing covariates for forecast models used in stock-recruit. It build upon prior work that identified and tested covariates using historical data, now shifting focus to how those covariates are adapted for use in forecast scenarios.

Some covariates were selected and evaluated based on literature review and expert input, followed by testing with historical data using leave-one-out (LOO) analysis. As we transition to forecast applications.

As we transition to forecast application, we need to find out if the data for a given covariate will be available at the time of forecasting. If yes, the covariate will be included in the forecast model using the same structure as the historical covariate. If the answer is no, meaning the covariate data will not be available during the forecaste period, then two strategies are considered:

  1 Use continuous forecast data, if available
  2 Create a discrete covariate based on historical data: restructure and bin the variable into categories based on historical conditions (e.g. high, medium, low)

#TODO Notes of what to include
- Describe how this forecast phase fits in with previous work on selecting covariates for stock recruit model and how it is different 
- highlight that some of the historical covariates that we have already tested will be the same structure as used in forecast models (e.g. like the spawning/incubating lifestage variables)
- Define what we mean by "scenario" or "continuous"
- When data for a covariate are not available, there are two options for the forecast model. We are focusing on the scenario type of variable

TODO include lucidapp diagram (https://lucid.app/lucidchart/54013423-12f2-42cc-a6cb-e9097fea1ad7/edit?beaconFlowId=21FC89EB4FE4986F&invitationId=inv_80180167-225e-4c43-9082-67bdc58283b2&page=0_0#)

## Covariates included in forecast models

TODO insert table that lists the covariates we are currently including in forecast models


```{r echo=FALSE}
covariate_table <- tibble::tibble(
  name = c("spawning/incubation minimum flow",
    "spawning/incubation maximum flow",
    "spawning/incubation maximum temperature",
    "above 13C threshold",
    "3-category water year type", 
    "3-category flow exceedance year type",
    "monthly reservoir storage",
    "monthly peak flow"),
  description = c("Use daily max flows for the spawning/incubation time period (Aug-Dec) and then calculate the minimum. This variable is available for all 4 time periods and would be the same because we are using data from the previous Aug-Dec.",
                  "Use daily max flows for the spawning/incubation time period (Aug-Dec) and then calculate the maximum. This variable is available for all 4 time periods and would be the same because we are using data from the previous Aug-Dec.",
                  "Summarizes the weekly maximum temperature for each stream (meaning it finds the max across all sites/subsites) within the spawning period. Note that the Sacramento River temperature data does not currently include a daily maximum so the weekly max is the max of the mean. An annual value is calculated by taking the max of the weekly max. This variable is available for all 4 time periods and would be the same because we are using data from the previous Aug-Dec.",
                  "This covariate is defined as the week of the year when the 7DADM is above 13C. Data are filtered to Mar-Dec because this is the time period where spring run are in the tributaries and may be experiencing temperature stress.\nNote, we currently do not have max daily temperatures for the Sacramento so mainstem is not included. This variable is available for all 4 time periods and would be the same because we are using data from the previous Aug-Dec.",
                  "Use water year type from CDEC for the Sacramento Valley and aggregate into 3 categories: C, D/BN/AN, W. This is a scenario based covariate meaning we do not need any data for the forecast. All 3 categories would be run for the forecast.",
                  "Use the flow exceedance methodology provided by the CDFW Instream Flow team (find mean annual flow by water year for each stream and rank the water years where the top 33% are wet, middle are average, bottom are dry) to categorize years for each stream into 3 categories: wet, average, dry",
                  "Using reservoir storage data, calculate the monthly max storage. For each JPE date we would use data from the month prior (e.g for Jan 1 it would be average for Dec)",
                  "Calculate the peak flow for each watershed and month. This would be different based on JPE date"))

covariate_table
```

Note that this covariate list will be iteratively updated and improved

# Preparing covariates

## Continuous variables

### Spawning and incubation flow variables

- min flow: Use daily max flows for the spawning/incubation time period (Aug-Dec) and then calculate the minimum
- max flow: Use daily max flows for the spawning/incubation time period (Aug-Dec) and then calculate the maximum

```{r, include = F}
si_min_flow <- sr_covariates |> 
filter(lifestage == "spawning and incubation", covariate_structure == "min_flow") |> 
  as_tibble() |> 
  mutate(name = "si_min_flow",
         water_year = NA,
         jpe_date = NA_Date_,
         value = as.character(value)) |> 
  select(name, year, water_year, stream, jpe_date, value) |> 
  glimpse()

si_max_flow <- sr_covariates |> 
filter(lifestage == "spawning and incubation", covariate_structure == "max_flow") |> 
  as_tibble() |> 
  mutate(name = "si_max_flow",
         water_year = NA,
         jpe_date = NA_Date_,
         value = as.character(value)) |> 
  select(name, year, water_year, stream, jpe_date, value)
```

### Spawning and incubation temperature variables

- max temp: Summarizes the weekly maximum temperature for each stream (meaning it finds the max across all sites/subsites) within the spawning period. Note that the Sacramento River temperature data does not currently include a daily maximum so the weekly max is the max of the mean. An annual value is calculated by taking the max of the weekly max.
- above 13C threshold: This covariate is defined as the week of the year when the 7DADM is above 13C. Data are filtered to Mar-Dec because this is the time period where spring run are in the tributaries and may be experiencing temperature stress. This includes holding as well as spawning and incubation time period.

```{r, include = F}
si_max_temp <- sr_covariates |> 
filter(lifestage == "spawning and incubation", covariate_structure == "weekly_max_temp_max") |>  
  as_tibble() |> 
  mutate(name = "si_max_temp",
         water_year = NA,
         jpe_date = NA_Date_,
         value = as.character(value)) |> 
  select(name, year, water_year, stream, jpe_date, value) |> 
  glimpse()

above_13 <- sr_covariates |> 
  filter(covariate_structure == "above_13_temp_week") |>
  as_tibble() |> 
  mutate(name = "above_13",
         water_year = NA,
         jpe_date = NA_Date_,
         value = as.character(value)) |>
  select(name, year, water_year, stream, jpe_date, value) 
```

### Reservoir storage

- monthly reservoir storage: Using reservoir storage data, calculate the monthly average storage. For each JPE date we would use data from the month prior (e.g for Jan 1 it would be average for Dec)
- This data contains monthly reservoir storage volumes (acre-feet) for Keswick Reservoir (KES), retrieved from the California Data Exchange Center (CDEC) operated by the California Department of Water Resources (DWR). The earliest data available is on 1965

```{r, include = F}
# Pull monthly reservoir storage: https://cdec.water.ca.gov/dynamicapp/QueryMonthly?s=KES

rs_monthly_raw <- cdec_query(station = "KES", sensor = "15", dur_code = "M", start_date = "1965-10-01")

rs_monthly <- rs_monthly_raw |> 
  mutate(date = as.Date(datetime),
         year = year(date),
         value = as.character(parameter_value),
         name = "rs_monthly",
         water_year = NA,
         month = month(date),
         jpe_year = if_else(month == 1, year - 1, year),
         jpe_month = if_else(month == 1, 12L, month - 1L),
         jpe_date = make_date(year = jpe_year, month = jpe_month),
         # jpe_date = if_else(month == 1, 12L, month - 1L), # if we only want the month
         water_year = NA,
         stream = "shasta dam") |> 
  filter(month %in% c(12, 1, 2, 3 )) |> 
  select(name, year, water_year, stream, jpe_date, value)  # should we add month as well?
 
```

## Scenario variales

### Water year type

  - This dataset provides annual Chronological Reconstructed Sacramento and San Joaquin Valley Water Year Hydrologic Classification Indices Based on measured unimpaired runoff (in million acre-feet). It was retrieved from the California Open Data Portal
  
```{r, include = F}
# https://data.ca.gov/dataset/cdec-water-year-type-dataset/resource/301aaef5-940d-4915-8ed6-baada4e101f5). Add on more recent years (need to find where best to pull 2023-2025)
#Process data into 3 categories: aggregate into 3 categories: C, D/BN/AN, W
wy_url <- "https://data.ca.gov/datastore/dump/301aaef5-940d-4915-8ed6-baada4e101f5?format=csv"

wy_raw <- read_csv(wy_url)

wy <- wy_raw |> 
  mutate(wy_type = case_when(WYT %in% c("D", "BN", "AN") ~ "D/BN/AN",
                             T ~ WYT),
         year = NA,
         water_year = WY,
         name = "3_category_wy_type",
         stream = NA,
         jpe_date = NA_Date_,
         value = NA) |>
  select(name, year, water_year, stream, jpe_date, value) 
```

### Flow year type

```{r, include = F}
# Connect to the work Badhia did to create "flow exceedance" water year types based on CDFW calculations
# We can either source that script, or move the code here - ashley and badhia to discuss
gage_ids <- c(
  Battle = "11376550",
  Butte = "11390000",
  Clear = "11372000",
  Deer = "11383500",
  Feather_LFC = "11407000",
  Mill = "11381500",
  Yuba = "11421000",
  Knights_Landing = "11390500"
)

start_date <- format(Sys.Date() - 30*365, "%Y-%m-%d")  # ~30 years ago
end_date <- format(Sys.Date(), "%Y-%m-%d")

flow_list <- lapply(gage_ids, function(site) {
  readNWISdv(siteNumbers = site, parameterCd = "00060",
             startDate = start_date, endDate = end_date)
})

combined_flow <- bind_rows(
  lapply(names(flow_list), function(name) {
    flow_list[[name]] |>
      mutate(
        date = as.Date(Date),
        flow_cfs = X_00060_00003,
        site_name = name,
        month = month(date),
        year = year(date),
        water_year = ifelse(lubridate::month(date) >= 10,
                            lubridate::year(date) + 1,
                            lubridate::year(date))) |>
      select(site_name, date, flow_cfs, month, year, water_year)
  }))

mean_discharge_by_site <- combined_flow |>
  group_by(site_name, water_year) |>
  summarize(mean_discharge = mean(flow_cfs, na.rm = TRUE), .groups = "drop")

# rank and assign water year type within each stream
water_year_types <- mean_discharge_by_site |>
  group_by(site_name) |>
  arrange(desc(mean_discharge)) |>
  mutate(rank = row_number(),
         n_years = n(),  # total water years per site
         water_year_type = case_when(rank <= n_years / 3 ~ "Wet",
                                     rank > 2 * n_years / 3 ~ "Dry",
                                     TRUE ~ "Average")) |>
  ungroup() |> 
  glimpse()

flow_water_year_type <- water_year_types |> 
  mutate(name = "flow_water_year_type", # confirm this is what we want to call it
         year = NA,
         stream = site_name,
         jpe_date = NA_Date_,
         value = as.character(water_year_type)) |> 
  select(name, year, water_year, stream, jpe_date, value)
```


# Combine and save data

```{r include=FALSE}
forecast_covariates <- bind_rows(si_min_flow, si_max_flow, si_max_temp, above_13, rs_monthly, flow_water_year_type, wy) |> glimpse()

#checks
unique(forecast_covariates$name)

# saveRDS(forecast_covariates, here::here("data", "forecast_covariates.RDS"))
```


TODO decide if we need to add a filter to the most recent year? Open question depending on how model code is set up